{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Processing 14/14"
    }
   ],
   "source": [
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "\n",
    "from preprocess import read_slang_words\n",
    "from preprocess import handle_emojis\n",
    "from preprocess import preprocess_word\n",
    "from preprocess import is_valid_word\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "\n",
    "MAX_TWEETS = 100\n",
    "\n",
    "\n",
    "ACCESS_TOKEN = '1213141429876248576-tebKwObkKvNxKTK0wHcGsC6us1yY0p'\n",
    "ACCESS_SECRET = 'VPq8rWcmHCJ1MK7UcCCNUnNDg37wUlCCUAY4oD0hVK8gR'\n",
    "CONSUMER_KEY = 'kDPOVCbOQBvleDpuWBMp7E8c3'\n",
    "CONSUMER_SECRET = '7zkS43Vdjx52lIBxMXoldehhAmWTygFq3I01vtUNatUeOk6xJM'\n",
    "\n",
    "\n",
    "CPT = 0\n",
    "data_folder = Path(\"../dataset\")\n",
    "slang_words = \"slang_words.csv\"\n",
    "slang_words_path = data_folder / slang_words\n",
    "slang_words_dict = read_slang_words(str(slang_words_path))\n",
    "stop_words_dict = set(stopwords.words('english'))\n",
    "hash_tag_list = [\"ISIS\", \"hillary clinton\", \"barack obama\", \"bernie sanders\"]\n",
    "fetched_tweets_filename = \"tweets.csv\"\n",
    "\n",
    "\n",
    "use_stemmer = False\n",
    "use_lemmatizer = True\n",
    "\n",
    "\n",
    "after_pre_traitement = \"tweets_after_pre_traitement.csv\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "   \n",
    "    processed_tweet = []\n",
    "    # Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    # Replaces URLs with the word URL\n",
    "    tweet = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', ' URL ', tweet)\n",
    "    # Replace @handle with the word USER_MENTION\n",
    "    tweet = re.sub(r'@[\\S]+', '', tweet)\n",
    "    # Replaces #hashtag with hashtag\n",
    "    tweet = re.sub(r'#(\\S+)', r' \\1 ', tweet)\n",
    "    # Remove RT (retweet)\n",
    "    tweet = re.sub(r'\\brt\\b', '', tweet)\n",
    "    # Replace 2+ dots with space\n",
    "    tweet = re.sub(r'\\.{2,}', ' ', tweet)\n",
    "    # Strip space, \" and ' from tweet\n",
    "    tweet = tweet.strip(' \"\\'')\n",
    "    # Replace emojis with either EMO_POS or EMO_NEG\n",
    "    tweet = handle_emojis(tweet)\n",
    "\n",
    "    # Replace multiple spaces with a single space\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "\n",
    "    words = tweet.split()\n",
    "    for word in words:\n",
    "        if word in slang_words_dict:\n",
    "            tweet = re.sub(word.encode('raw-unicode-escape'),slang_words_dict.get(word)+\" \", tweet)\n",
    "\n",
    "    \n",
    "    # Replace multiple spaces with a single space\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "\n",
    "    # delete stop words 3ayatni         \n",
    "    words = tweet.split() \n",
    "           \n",
    "    for word in words:\n",
    "        if word in stop_words_dict:\n",
    "            tweet = tweet.replace(\" \"+word+\" \", \" \")\n",
    "            \n",
    "            \n",
    "\n",
    "    #replace hmmm ta3 zabi\n",
    "    tweet = re.sub(r'h(m)+','',tweet)\n",
    "    \n",
    "\n",
    "    # Replace multiple spaces with a single space\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "\n",
    "    \n",
    "    words = tweet.split()\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "    for word in words:\n",
    "        word = preprocess_word(word)\n",
    "        if is_valid_word(word):\n",
    "\n",
    "            if use_lemmatizer and use_stemmer:\n",
    "                word = str(porter_lemmatizer.lemmatize(word))\n",
    "                word = str(porter_stemmer.stem(word))\n",
    "            elif use_stemmer:\n",
    "                word = str(porter_stemmer.stem(word))\n",
    "            elif use_lemmatizer:\n",
    "               word = str(porter_lemmatizer.lemmatize(word)) \n",
    "\n",
    "            processed_tweet.append(word)\n",
    "\n",
    "    return ' '.join(processed_tweet)\n",
    "\n",
    "# # # # TWITTER STREAMER # # # #\n",
    "class TwitterStreamer():\n",
    "    \"\"\"\n",
    "    Class for streaming and processing live tweets.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def stream_tweets(self, fetched_tweets_filename,after_pre_traitement,hash_tag_list):\n",
    "        # This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "        listener = StdOutListener(fetched_tweets_filename,after_pre_traitement)    \n",
    "        auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "        auth.set_access_token(ACCESS_TOKEN,ACCESS_SECRET)\n",
    "        stream = Stream(auth, listener)\n",
    "         # This line filter Twitter Streams to capture data by the keywords:\n",
    "        stream.filter(track=hash_tag_list,languages=[\"en\"])\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "# # # # TWITTER STREAM LISTENER # # # #\n",
    "class StdOutListener(StreamListener):\n",
    "    \"\"\"\n",
    "    This is a basic listener that just prints received tweets to stdout.\n",
    "    \"\"\"\n",
    "    def __init__(self, fetched_tweets_filename,after_pre_traitement):\n",
    "        self.fetched_tweets_filename = fetched_tweets_filename\n",
    "        self.after_pre_traitement = after_pre_traitement\n",
    "\n",
    "    def on_data(self, data):\n",
    "        global CPT\n",
    "        global MAX_TWEETS\n",
    "        try:\n",
    "            if CPT < MAX_TWEETS :\n",
    "                CPT += 1\n",
    "                all_data = json.loads(data)\n",
    "            \n",
    "                tweet_text = all_data['text'].encode('utf-8')\n",
    "                ##print (tweet_text)\n",
    "                tweet_id = all_data['id']\n",
    "           \n",
    "               \n",
    "                processed_tweet = preprocess_tweet(tweet_text)\n",
    "                with open(self.fetched_tweets_filename, 'a+') as tf:\n",
    "                    tf.write('%s,%s\\n' %(str(tweet_id), tweet_text))\n",
    "                    \n",
    "                    \n",
    "                    with open(self.after_pre_traitement, 'a+') as tfclean:\n",
    "                        if processed_tweet!=\"\": \n",
    "                            tfclean.write('%s,%s\\n' %(str(tweet_id),processed_tweet))\n",
    "                        \n",
    "                return True\n",
    "            else:\n",
    "                exit\n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data %s\" % str(e))\n",
    "        return True\n",
    "          \n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    " \n",
    "   \n",
    "    if use_lemmatizer and use_stemmer:\n",
    "        porter_lemmatizer = WordNetLemmatizer() \n",
    "        porter_stemmer = PorterStemmer()\n",
    "    elif use_lemmatizer :\n",
    "        porter_lemmatizer = WordNetLemmatizer() \n",
    "    elif use_stemmer :\n",
    "        porter_stemmer = PorterStemmer()\n",
    "    \n",
    "    \n",
    "    twitter_streamer = TwitterStreamer()\n",
    "    twitter_streamer.stream_tweets(fetched_tweets_filename,after_pre_traitement, hash_tag_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2.7.17 64-bit",
   "language": "python",
   "name": "python271764bite386401ad77d4478b4ce18369caabcd9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}